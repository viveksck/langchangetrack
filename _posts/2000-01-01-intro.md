---
title: "Abstract"
bg: white
color: black
style: justify 
---

# Abstract

![alt-text]({{ site.baseurl }}/img/gay_invisible.png)

We propose a new computational approach for tracking and detecting statistically significant linguistic shifts in the meaning and usage of words. 
Such linguistic shifts are especially prevalent on the Internet, where the rapid exchange of ideas can quickly change a wordâ€™s meaning. 
Our meta-analysis approach constructs property time series of word usage, and then uses statistically sound change point detection algorithms to identify significant linguistic shifts.

We consider and analyze three approaches of increasing complexity to generate such linguistic property time series, the culmination of which uses distributional characteristics inferred from word co-occurrences. Using recently proposed deep neural language models, we first train vector representations of words for each time period. Second, we warp the vector spaces into one unified coordinate system. Finally, we construct a distance-based distributional time series for each word to track its linguistic displacement over time.

We demonstrate that our approach is scalable by tracking linguistic change across years of micro-blogging using Twitter, a decade of product reviews using a corpus of movie reviews from Amazon, and a century of written books using the Google Book-ngrams. Our analysis reveals interesting patterns of language usage change commensurate with each medium.

A copy of the paper is available [here]({{ site.baseurl }}/data/kulkarni.pdf)

<span id="forkongithub">
  <a href="{{ site.source_link }}" class="bg-blue">
    Fork me on GitHub
  </a>
</span>
